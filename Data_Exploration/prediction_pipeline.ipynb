{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5591114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb3f1823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LIST\n",
    "#1- Change reading files to filter pdfs.\n",
    "#2- Access to the image classification end point\n",
    "#3- Create a JSON input for the endpoint (with the image)\n",
    "#4- Retrieve prediction\n",
    "#5- Store the prediction in a new BQ table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540a427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18c48bdc",
   "metadata": {},
   "source": [
    "# Predictions Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d750763",
   "metadata": {},
   "source": [
    "## 1. Notebook Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d68ec0",
   "metadata": {},
   "source": [
    "### 1.1. Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20694329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries:\n",
    "import os\n",
    "import io\n",
    "#import glob\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "# Dealing with images:\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Google APIs:\n",
    "from google.cloud import storage\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "# Libraries for string filtering:\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "# Libraries for image encoding\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Specific PDF libraries:\n",
    "#!conda install -c conda-forge poppler\n",
    "# !sudo apt-get install -y poppler-data\n",
    "# !sudo apt-get install -y poppler-utils\n",
    "# !pip install pdf2image\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1b2e5",
   "metadata": {},
   "source": [
    "### 1.2. Setting Notebook Inputs\n",
    "#### 1.2.1 Google Cloud Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3985cd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ai]\n",
      "region = us-central1\n",
      "[compute]\n",
      "region = us-central1\n",
      "[core]\n",
      "account = 136021895401-compute@developer.gserviceaccount.com\n",
      "disable_usage_reporting = True\n",
      "project = qwiklabs-gcp-00-373ac55d0e0a\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bb3468c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'qwiklabs-gcp-00-373ac55d0e0a'\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'qwiklabs-gcp-00-373ac55d0e0a'\n",
    "\n",
    "TEMP_FOLDER = './temp'\n",
    "#PDF_FOLDER = os.path.join(TEMP_FOLDER, 'pdf')\n",
    "#PNG_FOLDER = os.path.join(TEMP_FOLDER, 'png')\n",
    "#CSV_FOLDER = os.path.join(TEMP_FOLDER, 'csv')\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694b97c0",
   "metadata": {},
   "source": [
    "#### 1.2.2. Image Classification Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce192ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_ENDPOINT_ID=\"7257673944809865216\"\n",
    "IC_PROJECT_ID=\"136021895401\"\n",
    "IC_INPUT_DATA_FILE=\"INPUT-JSON\"\n",
    "\n",
    "# Example of instance:\n",
    "# {\n",
    "#  \"instances\": [{\n",
    "#    \"content\": \"YOUR_IMAGE_BYTES\"\n",
    "#  }],\n",
    "#   \"parameters\": {\n",
    "#     \"confidenceThreshold\": 0.5,\n",
    "#     \"maxPredictions\": 5\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcc2b80",
   "metadata": {},
   "source": [
    "#### 1.2.3. Object Detection Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c52cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_ENDPOINT_ID=\"2074030773706424320\"\n",
    "OD_PROJECT_ID=\"136021895401\"\n",
    "OD_INPUT_DATA_FILE=\"INPUT-JSON\"\n",
    "\n",
    "# Example of instance:\n",
    "# {\n",
    "#  \"instances\": [{\n",
    "#    \"content\": \"YOUR_IMAGE_BYTES\"\n",
    "#  }],\n",
    "#   \"parameters\": {\n",
    "#     \"confidenceThreshold\": 0.5,\n",
    "#     \"maxPredictions\": 5\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136f028e",
   "metadata": {},
   "source": [
    "## 2 Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32505660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c48705cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_bucket(bucket_name, dest_folder):\n",
    "    '''@brief! Function that downloads a list of files from a bucket.\n",
    "\n",
    "    @param: bucket: (string) Bucket name.\n",
    "    @param: dest_folder: (string) Folder where files are downloaded.\n",
    "    '''\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "        \n",
    "    new_file_lst = []\n",
    "    # Instantiating client:\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    blob_list  = [blob for blob in list(bucket.list_blobs()) if blob.name.startswith(\"labeled_patents/pdf/\") and blob.name.endswith(\".pdf\")]\n",
    "\n",
    "    # Saving blob into the destination folder:\n",
    "    for blob in blob_list:\n",
    "        # Saving blob into a filename:\n",
    "        _, name = os.path.split(blob.name)\n",
    "        new_fname = os.path.join(dest_folder, name)\n",
    "        blob.download_to_filename(new_fname)\n",
    "        new_file_lst.append(new_fname)\n",
    "    \n",
    "    # TODO: A check of the downloaded files should be performed!! Maybe is just \n",
    "    # reading the files of the folder since if it is a temporal folder, every time\n",
    "    # the pipeline is executed, the folder is created empty:\n",
    "    #os.listdir(dest_folder) or similar\n",
    "    print('Number of files downloaded: {:d}'.format(len(new_file_lst)))\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9cb95bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images_in_path(path):\n",
    "    '''@brief! Function to encode an image of each pdf to be used as instance \n",
    "    for a AutoML mode.\n",
    "        \n",
    "    @param: file_lst (list of strings) PDF file names to be transformed.\n",
    "    '''\n",
    "    file_lst = [os.path.join(path, file) for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n",
    "    \n",
    "    encoded_img_lst = []\n",
    "    for file in file_lst:\n",
    "        image = convert_from_path(file)\n",
    "        image = image[0]                # Only the firs page is going to be analyzed.\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "        encoded_img_lst.append(base64.b64encode(img_byte_arr).decode(\"utf-8\"))\n",
    "\n",
    "    return encoded_img_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300f796a",
   "metadata": {},
   "source": [
    "### 2. Pipeline Functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ee9b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download files to temp\n",
    "dest_folder = \"./temp\"\n",
    "# if download_files_from_bucket(BUCKET, dest_folder):\n",
    "    # transform to images\n",
    "imgs = encode_images_in_path(dest_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589d2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: save images to temp\n",
    "# TODO: upload to storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a35e65e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "gcs_img_path = f\"gs:/{PROJECT}/{BUCKET}/labeled_patents/images\"\n",
    "fp = \"images_icn.jsonl\"\n",
    "\n",
    "def save_jsonl(fp, json_file):\n",
    "    # needs .jl suffix\n",
    "    d = json.dumps(json_file)+\"\\n\"\n",
    "    d = d.encode('utf8')\n",
    "    try:\n",
    "        with open(fp, \"ab\") as f:\n",
    "            f.write(d)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: {e}\\n{sys.exc_info()}\\n{traceback.format_exc()}\")\n",
    "\n",
    "def create_jsonl(gcs_img_path,fp):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET)\n",
    "    # create jsonl\n",
    "    blob_list  = [blob.name for blob in list(bucket.list_blobs()) if blob.name.startswith(\"labeled_patents/images\") and blob.name.endswith(\".png\")]\n",
    "    \n",
    "    for filename in blob_list:\n",
    "        temp_json = {\"content\": f\"gs://{BUCKET}/{filename}\", \"mimeType\": \"image/png\"}\n",
    "        save_jsonl(fp, temp_json)\n",
    "    \n",
    "create_jsonl(gcs_img_path, fp)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7991bb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./images_icn.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 44.8 KiB/ 44.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/44.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp ./images_icn.jsonl gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1727f572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648\n",
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648')\n",
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/1748166313559195648?project=136021895401\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob run completed. Resource name: projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648\n",
      "batch_img_classification\n",
      "projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648\n",
      "JobState.JOB_STATE_SUCCEEDED\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.jobs.BatchPredictionJob object at 0x7f370195f850> \n",
       "resource name: projects/136021895401/locations/us-central1/batchPredictionJobs/1748166313559195648"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import base64\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "\n",
    "def create_batch_prediction_job_sample(\n",
    "    project='qwiklabs-gcp-00-373ac55d0e0a',\n",
    "    location='us-central1',\n",
    "    model_resource_name='8925034949820547072',\n",
    "    job_display_name='batch_img_classification',\n",
    "    gcs_source='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images_icn.jsonl',\n",
    "    gcs_destination='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/img_class_preds',\n",
    "):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    my_model = aiplatform.Model(model_resource_name)\n",
    "\n",
    "    batch_prediction_job = my_model.batch_predict(\n",
    "        job_display_name=job_display_name,\n",
    "        gcs_source=gcs_source,\n",
    "        gcs_destination_prefix=gcs_destination,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "    batch_prediction_job.wait()\n",
    "\n",
    "    print(batch_prediction_job.display_name)\n",
    "    print(batch_prediction_job.resource_name)\n",
    "    print(batch_prediction_job.state)\n",
    "    return batch_prediction_job\n",
    "\n",
    "create_batch_prediction_job_sample(\n",
    "    project='qwiklabs-gcp-00-373ac55d0e0a',\n",
    "    location='us-central1',\n",
    "    model_resource_name='8925034949820547072',\n",
    "    job_display_name='batch_img_classification',\n",
    "    gcs_source='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images_icn.jsonl',\n",
    "    gcs_destination='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/img_class_preds',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cfac0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
