{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Object Detection with AutoML Vision</b>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>Learning Objectives</b> ##\n",
    "\n",
    "1. Learn how to create and import an image dataset to AutoML Vision\n",
    "1. Learn how to train an AutoML object detection model\n",
    "1. Learn how to evaluate a model trained with AutoML\n",
    "1. Learn how to deploy a model trained with AutoML\n",
    "1. Learn how to predict on new test data with AutoML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use AutoML Vision Object Detection to train a machine learning model capable of detecting multiple objects in a given image and provides information about the objects and their location within the image.\n",
    "\n",
    "We will start by creating a dataset for AutoML Vision and then import a publicly available set of images into it. After that we will train, evaluate and deploy the AutoML model trained for this dataset. Ultimately we show how to send prediction requests to our model through the deployed API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = !gcloud config get-value project # returns SList\n",
    "PROJECT_ID = PROJECT_ID[0] # gets first element in list -> str\n",
    "SERVICE_ACCOUNT = \"sa-objectdetection\" # Replace with a name of your choice\n",
    "ZONE = \"us-central1\"# Make sure the zone is set to \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client(project=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"\n",
    "#standardSQL\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    `qwiklabs-gcp-00-373ac55d0e0a.labeled_patents.figures`\n",
    "\"\"\"\n",
    "\n",
    "figures = bq.query(query_string).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_modified = figures.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_gcs_path(original):\n",
    "    split_path = os.path.split(original)\n",
    "    new_path = os.path.join(\"gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images\" ,split_path[1])\n",
    "    return new_path\n",
    "\n",
    "def get_filename(original):\n",
    "    return os.path.basename(original)\n",
    "\n",
    "def change_extension(original):\n",
    "    return original[:-3] + \"png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://gcs-public-data--labeled-patents/espacenet_en66.pdf'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figures.loc[0, \"gcs_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_modified[\"gcs_path\"] = figures_modified[\"gcs_path\"].apply(change_gcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_modified[\"gcs_path\"] = figures_modified[\"gcs_path\"].apply(change_extension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images/espacenet_en43.png'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figures_modified.loc[1, \"gcs_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_modified[\"label\"] = \"figure\"\n",
    "figures_modified[\"empty1\"] = None\n",
    "figures_modified[\"empty2\"] = None\n",
    "figures_modified[\"empty3\"] = None\n",
    "figures_modified[\"empty4\"] = None\n",
    "figures_modified[\"assignment\"] = \"UNASSIGNED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [ 'assignment', 'gcs_path', 'label', 'x_relative_min', 'y_relative_min', \"empty1\",\"empty2\", 'x_relative_max',\n",
    "       'y_relative_max', \"empty3\", \"empty4\"]\n",
    "figures_modified = figures_modified[cols]\n",
    "\n",
    "#  (x_relative_min, y_relative_min,,,x_relative_max,y_relative_max,,),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>assignment</th>\n",
       "      <th>gcs_path</th>\n",
       "      <th>label</th>\n",
       "      <th>x_relative_min</th>\n",
       "      <th>y_relative_min</th>\n",
       "      <th>empty1</th>\n",
       "      <th>empty2</th>\n",
       "      <th>x_relative_max</th>\n",
       "      <th>y_relative_max</th>\n",
       "      <th>empty3</th>\n",
       "      <th>empty4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.356322</td>\n",
       "      <td>0.745275</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.669691</td>\n",
       "      <td>0.936856</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.395039</td>\n",
       "      <td>0.682131</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.640048</td>\n",
       "      <td>0.935567</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.358137</td>\n",
       "      <td>0.637457</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.664247</td>\n",
       "      <td>0.935567</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.539020</td>\n",
       "      <td>0.600945</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.882638</td>\n",
       "      <td>0.955326</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.531155</td>\n",
       "      <td>0.597079</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.888082</td>\n",
       "      <td>0.923110</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.366001</td>\n",
       "      <td>0.637887</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.660012</td>\n",
       "      <td>0.734107</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.531760</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.885662</td>\n",
       "      <td>0.826890</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.528736</td>\n",
       "      <td>0.600945</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.889292</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.156080</td>\n",
       "      <td>0.710052</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.856019</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>UNASSIGNED</td>\n",
       "      <td>gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.259528</td>\n",
       "      <td>0.673110</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0.751966</td>\n",
       "      <td>0.940722</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    assignment                                           gcs_path   label  \\\n",
       "0   UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "1   UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "2   UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "3   UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "4   UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "..         ...                                                ...     ...   \n",
       "86  UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "87  UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "88  UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "89  UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "90  UNASSIGNED  gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_pate...  figure   \n",
       "\n",
       "    x_relative_min  y_relative_min empty1 empty2  x_relative_max  \\\n",
       "0         0.356322        0.745275   None   None        0.669691   \n",
       "1         0.395039        0.682131   None   None        0.640048   \n",
       "2         0.358137        0.637457   None   None        0.664247   \n",
       "3         0.539020        0.600945   None   None        0.882638   \n",
       "4         0.531155        0.597079   None   None        0.888082   \n",
       "..             ...             ...    ...    ...             ...   \n",
       "86        0.366001        0.637887   None   None        0.660012   \n",
       "87        0.531760        0.587629   None   None        0.885662   \n",
       "88        0.528736        0.600945   None   None        0.889292   \n",
       "89        0.156080        0.710052   None   None        0.856019   \n",
       "90        0.259528        0.673110   None   None        0.751966   \n",
       "\n",
       "    y_relative_max empty3 empty4  \n",
       "0         0.936856   None   None  \n",
       "1         0.935567   None   None  \n",
       "2         0.935567   None   None  \n",
       "3         0.955326   None   None  \n",
       "4         0.923110   None   None  \n",
       "..             ...    ...    ...  \n",
       "86        0.734107   None   None  \n",
       "87        0.826890   None   None  \n",
       "88        0.951890   None   None  \n",
       "89        0.951890   None   None  \n",
       "90        0.940722   None   None  \n",
       "\n",
       "[91 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figures_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "figures_modified.to_csv(\"./dataset/object_detection.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./dataset/object_detection.csv [Content-Type=text/csv]...\n",
      "/ [1/1 files][ 12.9 KiB/ 12.9 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/12.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil -m cp ./dataset/object_detection.csv gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/object_detection.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b>AutoML Vision Setup</b> ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin make sure you have [created a project on the GCP Console](https://cloud.google.com/vision/automl/object-detection/docs/before-you-begin) and enabled the AutoML and Cloud Storage APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <b> Install AutoML and Cloud Storage package </b> ###\n",
    "<b>Caution: Run the following command and restart the kernel afterwards.</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting google-cloud-automl==1.0.1\n",
      "  Downloading google_cloud_automl-1.0.1-py2.py3-none-any.whl (372 kB)\n",
      "\u001b[K     |████████████████████████████████| 372 kB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-automl==1.0.1) (1.31.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (2.25.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (21.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (3.16.0)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (1.33.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (2021.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (49.6.0.post20210108)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (1.53.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (1.38.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (4.7.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (1.26.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google-cloud-automl==1.0.1) (2021.5.30)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: google-cloud-automl\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Successfully installed google-cloud-automl-1.0.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep google-cloud-automl==1.0.1 || pip install google-cloud-automl==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Collecting google-cloud-storage==1.27.0\n",
      "  Downloading google_cloud_storage-1.27.0-py2.py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 5.2 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage==1.27.0) (1.7.1)\n",
      "Collecting google-resumable-media<0.6dev,>=0.5.0\n",
      "  Downloading google_resumable_media-0.5.1-py2.py3-none-any.whl (38 kB)\n",
      "Requirement already satisfied: google-auth<2.0dev,>=1.11.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-storage==1.27.0) (1.33.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (0.2.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (4.2.2)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.21.0 in /home/jupyter/.local/lib/python3.7/site-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (1.31.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (3.16.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (2.25.1)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (2021.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/conda/lib/python3.7/site-packages (from google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (21.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=14.3->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (2.4.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.11.0->google-cloud-storage==1.27.0) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (1.26.6)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.21.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage==1.27.0) (2.10)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Installing collected packages: google-resumable-media, google-cloud-storage\n",
      "  Attempting uninstall: google-resumable-media\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33m    WARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "    Found existing installation: google-resumable-media 1.3.1\n",
      "    Uninstalling google-resumable-media-1.3.1:\n",
      "      Successfully uninstalled google-resumable-media-1.3.1\n",
      "  Attempting uninstall: google-cloud-storage\n",
      "    Found existing installation: google-cloud-storage 1.41.1\n",
      "    Uninstalling google-cloud-storage-1.41.1:\n",
      "      Successfully uninstalled google-cloud-storage-1.41.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-cloud 0.1.14 requires tensorboard>=2.3.0, but you have tensorboard 2.1.1 which is incompatible.\n",
      "google-cloud-bigquery 2.20.0 requires google-resumable-media<2.0dev,>=0.6.0, but you have google-resumable-media 0.5.1 which is incompatible.\n",
      "google-cloud-aiplatform 1.1.1 requires google-cloud-storage<2.0.0dev,>=1.32.0, but you have google-cloud-storage 1.27.0 which is incompatible.\n",
      "caip-notebooks-serverextension 1.0.0 requires pyjwt>=2.0.0, but you have pyjwt 1.6.4 which is incompatible.\u001b[0m\n",
      "Successfully installed google-cloud-storage-1.27.0 google-resumable-media-0.5.1\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-estimator (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -ensorboard (/opt/conda/lib/python3.7/site-packages)\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip freeze | grep google-cloud-storage==1.27.0 || pip install google-cloud-storage==1.27.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-11 14:32:20.328225: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2021-08-11 14:32:20.328360: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2021-08-11 14:32:20.328371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import automl\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Set the correct environment variables </b> ###\n",
    "The following variables should be updated according to your own environment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "The following variables are computed from the one you set above, and should not be modified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sa-objectdetection@qwiklabs-gcp-00-373ac55d0e0a.iam.gserviceaccount.com\n",
      "qwiklabs-gcp-00-373ac55d0e0a\n"
     ]
    }
   ],
   "source": [
    "PWD = os.path.abspath(os.path.curdir)\n",
    "\n",
    "SERVICE_KEY_PATH = os.path.join(PWD, \"{0}.json\".format(SERVICE_ACCOUNT))\n",
    "SERVICE_ACCOUNT_EMAIL=\"{0}@{1}.iam.gserviceaccount.com\".format(SERVICE_ACCOUNT, PROJECT_ID)\n",
    "print(SERVICE_ACCOUNT_EMAIL)\n",
    "print(PROJECT_ID)\n",
    "\n",
    "# Exporting the variables into the environment to make them available to all the subsequent cells\n",
    "os.environ[\"PROJECT_ID\"] = PROJECT_ID\n",
    "os.environ[\"SERVICE_ACCOUNT\"] = SERVICE_ACCOUNT\n",
    "os.environ[\"SERVICE_KEY_PATH\"] = SERVICE_KEY_PATH\n",
    "os.environ[\"SERVICE_ACCOUNT_EMAIL\"] = SERVICE_ACCOUNT_EMAIL\n",
    "os.environ[\"ZONE\"] = ZONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Switching the right project and zone</b> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n",
      "Updated property [compute/region].\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud config set project $PROJECT_ID\n",
    "gcloud config set compute/region $ZONE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Create a service account and generate service key</b> ###\n",
    "\n",
    "\n",
    "Before we can run our program we need to get it authenticated. For that, we first need to generate a service account.\n",
    "A service account is a special type of Google account intended for non-human users (i.e., services) that need to authenticate and be authorized to access data through Google APIs (in our case the AutoML and Cloud Storage API). After the service account has been created it needs to be associated with a service account key, which is a json file holding everything that the client needs to authenticate with the service endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        sa-objectdetection@qwiklabs-gcp-00-373ac55d0e0a.iam.gserviceaccount.com            False\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud iam service-accounts list | grep $SERVICE_ACCOUNT ||\n",
    "gcloud iam service-accounts create $SERVICE_ACCOUNT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service key: /home/jupyter/ASL_DocProcessing_2021/Data_Exploration/sa-objectdetection.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "created key [470db43c16aa290832a4301c97685aa461f098eb] of type [json] as [/home/jupyter/ASL_DocProcessing_2021/Data_Exploration/sa-objectdetection.json] for [sa-objectdetection@qwiklabs-gcp-00-373ac55d0e0a.iam.gserviceaccount.com]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "test -f $SERVICE_KEY_PATH || \n",
    "gcloud iam service-accounts keys create $SERVICE_KEY_PATH \\\n",
    "  --iam-account $SERVICE_ACCOUNT_EMAIL\n",
    "\n",
    "echo \"Service key: $(ls $SERVICE_KEY_PATH)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Make the key available to google clients for authentication</b> ###\n",
    "AutoML API will check this environement variable to see where the key is located and use it to authenticate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = SERVICE_KEY_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Grant service account required role permissions</b> ###\n",
    "\n",
    "After we have created our service account and associated it with the service key we need to assign some permissions through a role. For this example we only need to grant our service account the automl and storage admin role so it has permission to complete specific actions on the resources of your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# gcloud projects add-iam-policy-binding $PROJECT_ID \\\n",
    "#  --member \"serviceAccount:$SERVICE_ACCOUNT_EMAIL\" \\\n",
    "#  --role \"roles/automl.admin\" \\\n",
    "#  --role \"roles/storage.admin\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 1: Preparing and formatting training data</b> ##\n",
    "\n",
    "The first step in creating a custom model with the AutoML Vision is to prepare the training data. In this case the training dataset that is composed of images along with information identifying the location (through bounding boxes coordinates) and type of objects (through labels) in the images. \n",
    "Here are some constraints some general rules for preparing an AutoML object detection dataset:\n",
    "\n",
    "* The following image formats are supported: JPEG, PNG, GIF, BMP, or ICO. Maximum file size is 30MB per image.\n",
    "\n",
    "* AutoML Vision models can not generally predict labels that humans can't assign. So, if a human can't be trained to assign labels by looking at the image for 1-2 seconds, the model likely can't be trained to do it either.\n",
    "\n",
    "* It is recommended to have about 1000 training images per label (i.e. object type you want to detect in the images). For each label you must have at least 10 images, each with at least one annotation (bounding box and the label). In general, the more images per label you have the better your model will perform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Training vs. evaluation datasets</b> ###\n",
    "\n",
    "When training machine learning models you typically divide the dataset usually into three separate datasets:\n",
    "\n",
    "1. a training dataset\n",
    "1. a validation dataset\n",
    "1. a test dataset\n",
    "\n",
    "A training dataset is used to build a model. The model being trained tries multiple parameters while searching for patterns in the training data. During the process of pattern identification, AutoML Vision Object Detection uses the validation dataset to test the parameters of the model. AutoML Vision Object Detection chooses the best-performing algorithms and patterns from all options identified during the training stage.\n",
    "\n",
    "After the best performing algorithms and patterns have been identified, they are tested for error rate, quality, and accuracy using the test dataset.\n",
    "\n",
    "Both a validation and a test dataset are used in order to avoid bias in the model. During the validation stage, optimal model parameters are used. Using these optimal model parameters can result in biased metrics. Using the test dataset to assess the quality of the model after the validation stage provides the training process with an unbiased assessment of the quality of the model.\n",
    "\n",
    "\n",
    "By default, AutoML Vision Object Detection splits your dataset randomly into 3 separate sets (you don't need to do it yourself!):\n",
    "\n",
    "* 80% of images are used for training.\n",
    "* 10% of images are used for hyper-parameter tuning and/or to decide when to stop training.\n",
    "* 10% of images are used for evaluating the model. These images are not used in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Create a CSV file with image URIs and labels</b> ###\n",
    "\n",
    "Once your image files have been uploaded to a Cloud Storage bucket (`gs://bucket-name-vcm`), you must create a CSV file that lists all of the URI of the uploaded images, along with bounding box information and the object labels. The dataset will contain one row per bounding box in the image, so an image that has two bounding boxes will have two corresponding rows in the CSV file sharing the same image URI. The CSV file can have any filename, must be in the same bucket as your image files, must be UTF-8 encoded, and must end with a `.csv` extension. \n",
    "\n",
    "\n",
    "In the example below, rows 1 and 2 reference the same image that has 2 annotations \n",
    "`(car,0.1,0.1,,,0.3,0.3,,)` and  `(bike,.7,.6,,,.8,.9,,)`. The first element of the annotation\n",
    "is the object label in the bounding box, while the rest are the coordinates of the bounding box\n",
    "within the image (see below for details).\n",
    "\n",
    "\n",
    "Row 3 refers to an image that has only 1 annotation `(car,0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.3)`, while row 4 references an image with no annotations.\n",
    "\n",
    "The first column corresponds to the data split, the second column to the image URI, and the last columns hold the annotations.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "TRAIN,gs://folder/image1.png,car,0.1,0.1,,,0.3,0.3,,\n",
    "TRAIN,gs://folder/image1.png,bike,.7,.6,,,.8,.9,,\n",
    "UNASSIGNED,gs://folder/im2.png,car,0.1,0.1,0.2,0.1,0.2,0.3,0.1,0.3\n",
    "TEST,gs://folder/im3.png,,,,,,,,,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row above has these columns:\n",
    "`\n",
    "1. <b>Which dataset is the content in the row being assigned to.</b> - `TRAIN`, `VALIDATE`, `TEST` or `UNASSIGNED`\n",
    "1. <b>What content is being annotated.</b> - It contains the GCS URI for the image\n",
    "1. <b>A label that identifies how the object is categorized.\n",
    "1. <b>A bounding box for an object in the image.</b>\n",
    "    \n",
    "\n",
    "The **bounding box** for an object can be specified in two ways:\n",
    "    \n",
    "    *  with only 2 vertices (consisting of a set of x and y coordinates) if they are diagonally opposite points of the rectangle \n",
    "```  \n",
    "(x_relative_min,y_relative_min,,,x_relative_max,y_relative_max,,)\n",
    "```   \n",
    "    * with all 4 vertices\n",
    "```    \n",
    "(x_relative_min,y_relative_min,x_relative_max,y_relative_min,x_relative_max,y_relative_max,x_relative_min,y_relative_max)\n",
    "```\n",
    "    \n",
    "Each vertex is specified by x, y coordinate values. These coordinates must be a float in the 0 to 1 range, where 0 represents the minimum x or y value, and 1 represents the greatest x or y value.\n",
    "\n",
    "For example, `(0,0)` represents the top left corner, and `(1,1)` represents the bottom right corner; a bounding box for the entire image is expressed as `(0,0,,,1,1,,)`, or `(0,0,1,0,1,1,0,1)`.\n",
    "\n",
    "AutoML API does not require a specific vertex ordering. Additionally, if 4 specified vertices don't form a rectangle parallel to image edges, AutoML API calculates and uses vertices that do form such a rectangle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a CSV file for unlabeled images stored in Cloud Storage ###\n",
    "\n",
    "If you already have unlabeled images uploaded to Cloud Storage and would like to generate a CSV pointing to them, run this code in Cloud Shell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "for f in $(gsutil ls gs://YOUR_BUCKET/YOUR_IMAGES_FOLDER/);\n",
    "do echo UNASSIGNED,$f;\n",
    "done >> labels.csv;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then copy the generated CSV file into a Google Storage Bucket:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```gsutil cp labels.csv gs://YOUR_BUCKET/labels.csv```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then after uploading the images to AutoML Object Detection, you can use Cloud Vision API's [Object Localizer](https://cloud.google.com/vision/docs/object-localizer) feature to help build your dataset by getting more generalized labels and bounding boxes for objects in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 2: Create a dataset</b> ##\n",
    "\n",
    "Next step is to create and name an empty dataset that will eventually hold the training data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: projects/136021895401/locations/us-central1/datasets/IOD1879712434462130176\n",
      "Dataset id: IOD1879712434462130176\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"docprocessing_objdet\" # Replace with desired dataset name\n",
    "display_name = \"patent_figures_dataset\"\n",
    "client = automl.AutoMlClient()\n",
    "\n",
    "# A resource that represents Google Cloud Platform location.\n",
    "project_location = client.location_path(PROJECT_ID, ZONE)\n",
    "metadata = automl.types.ImageObjectDetectionDatasetMetadata()\n",
    "dataset = automl.types.Dataset(\n",
    "    display_name=display_name,\n",
    "    image_object_detection_dataset_metadata=metadata,\n",
    ")\n",
    "\n",
    "# Create a dataset with the dataset metadata in the region.\n",
    "response = client.create_dataset(project_location, dataset)\n",
    "\n",
    "created_dataset = response.result()\n",
    "\n",
    "# Display the dataset information\n",
    "print(\"Dataset name: {}\".format(created_dataset.name))\n",
    "print(\"Dataset id: {}\".format(created_dataset.name.split(\"/\")[-1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 3: Import images into a dataset</b> ##\n",
    "\n",
    "\n",
    "After you have created a dataset, prepared and formated your training data, it's time to import that training data into our created dataset.\n",
    "\n",
    "In this notebook we will use a publicly available \"Salads\" training dataset that is located at `gs://cloud-ml-data/img/openimage/csv/salads_ml_use.csv`.\n",
    "\n",
    "This dataset contains images of salads with bounding boxes and labels around their ingredients (e.g., tomato, seafood, etc.).\n",
    "So the model we will train will be able to take as input the image of a salad and determine the ingredients composing the salad\n",
    "as well as the location of the ingredients on the salad image.\n",
    "\n",
    "Please note the import might take a couple of minutes to finish depending on the file size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPrecondition",
     "evalue": "400 No other operations should be working on projects/136021895401/locations/us-central1/datasets/IOD1879712434462130176.\nCurrently running operations on the dataset:\n\tprojects/136021895401/locations/us-central1/operations/IOD195032746924441600\nCall List Operation API to learn more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.FAILED_PRECONDITION\n\tdetails = \"No other operations should be working on projects/136021895401/locations/us-central1/datasets/IOD1879712434462130176.\nCurrently running operations on the dataset:\n\tprojects/136021895401/locations/us-central1/operations/IOD195032746924441600\nCall List Operation API to learn more details.\"\n\tdebug_error_string = \"{\"created\":\"@1628693756.305059441\",\"description\":\"Error received from peer ipv4:74.125.195.95:443\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1066,\"grpc_message\":\"No other operations should be working on projects/136021895401/locations/us-central1/datasets/IOD1879712434462130176.\\nCurrently running operations on the dataset:\\n\\tprojects/136021895401/locations/us-central1/operations/IOD195032746924441600\\nCall List Operation API to learn more details.\",\"grpc_status\":9}\"\n>",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21250/3858724576.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# # Import data from the input URI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_full_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing import...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/automl_v1/gapic/auto_ml_client.py\u001b[0m in \u001b[0;36mimport_data\u001b[0;34m(self, name, input_config, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m         operation = self._inner_api_calls[\"import_data\"](\n\u001b[0;32m--> 793\u001b[0;31m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    794\u001b[0m         )\n\u001b[1;32m    795\u001b[0m         return google.api_core.operation.from_gapic(\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0msleep_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mon_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mon_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m             )\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/retry.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, deadline, on_error)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;34m\"\"\"Wrapped function that adds timeout.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mFailedPrecondition\u001b[0m: 400 No other operations should be working on projects/136021895401/locations/us-central1/datasets/IOD1879712434462130176.\nCurrently running operations on the dataset:\n\tprojects/136021895401/locations/us-central1/operations/IOD195032746924441600\nCall List Operation API to learn more details."
     ]
    }
   ],
   "source": [
    "DATASET_ID = format(created_dataset.name.split(\"/\")[-1])\n",
    "DATASET_URI = \"gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/object_detection.csv\" \n",
    "\n",
    "# Get the full path of the dataset.\n",
    "dataset_full_id = client.dataset_path(\n",
    "    PROJECT_ID, ZONE, DATASET_ID\n",
    ")\n",
    "\n",
    "# Get the multiple Google Cloud Storage URIs\n",
    "path = DATASET_URI\n",
    "input_uris = path.split(\",\")\n",
    "gcs_source = automl.types.GcsSource(input_uris=input_uris)\n",
    "input_config = automl.types.InputConfig(gcs_source=gcs_source)\n",
    "\n",
    "# # Import data from the input URI\n",
    "response = client.import_data(dataset_full_id, input_config)\n",
    "\n",
    "print(\"Processing import...\")\n",
    "print(\"Data imported. {}\".format(response.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'qwiklabs-gcp-00-373ac55d0e0a'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: https://automl.googleapis.com/v1/projects/-gcp-00-373ac55d0e0a/locations/us-central1/operations/IOD195032746924441600: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# operation_full_id = \"projects/136021895401/locations/us-central1/operations/IOD195032746924441600\"\n",
    "# !https://automl.googleapis.com/v1/projects/${PROJECT_ID}/locations/us-central1/operations/IOD195032746924441600    \n",
    "# curl -X GET \\\n",
    "# -H \"Authorization: Bearer \"$(gcloud auth application-default print-access-token) \\\n",
    "# https://automl.googleapis.com/v1/projects/qwiklabs-gcp-00-373ac55d0e0a/locations/us-central1/operations/IOD195032746924441600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 4: Train your AutoML Vision model</b> ##\n",
    "\n",
    "Once you are happy with your created dataset you can proceed with training the model. <i>Please note</i> - training time takes approximately <b>1-3h</b>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Parameter to MergeFrom() must be instance of same class: expected google.cloud.automl.v1.ImageObjectDetectionModelMetadata got google.cloud.automl.v1.ImageObjectDetectionDatasetMetadata.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21250/197756276.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdisplay_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplay_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdataset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimage_object_detection_model_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Parameter to MergeFrom() must be instance of same class: expected google.cloud.automl.v1.ImageObjectDetectionModelMetadata got google.cloud.automl.v1.ImageObjectDetectionDatasetMetadata."
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"figure_objdet\" # Replace with desired model name\n",
    "\n",
    "# A resource that represents Google Cloud Platform location.\n",
    "\n",
    "project_location = client.location_path(PROJECT_ID, ZONE)\n",
    "dataset_id = \"IOD1879712434462130176\"\n",
    "\n",
    "# Leave model unset to use the default base model provided by Google\n",
    "# train_budget_milli_node_hours: The actual train_cost will be equal or\n",
    "# less than this value.\n",
    "# https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#imageobjectdetectionmodelmetadata\n",
    "training_metadata = automl.types.ImageObjectDetectionModelMetadata(\n",
    "    train_budget_milli_node_hours=24000\n",
    ")\n",
    "model = automl.types.Model(\n",
    "    display_name=display_name,\n",
    "    dataset_id=dataset_id,\n",
    "    image_object_detection_model_metadata=metadata,\n",
    ")\n",
    "\n",
    "# Create a model with the model metadata in the region.\n",
    "training_results = client.create_model(project_location, model)\n",
    "\n",
    "print(\"Training operation name: {}\".format(response.operation.name))\n",
    "print(\"Training started...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google.cloud.automl.v1.ImageObjectDetectionModelMetadata\n",
    "# google.cloud.automl.v1.ImageObjectDetectionDatasetMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### <b>Information about the trained model</b> ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_ID = format(model.name.split(\"/\")[-1])\n",
    "\n",
    "# Get the full path of the model.\n",
    "model_full_id = client.model_path(PROJECT_ID, ZONE, MODEL_ID)\n",
    "model = client.get_model(model_full_id)\n",
    "\n",
    "# Retrieve deployment state.\n",
    "if model.deployment_state == automl.enums.Model.DeploymentState.DEPLOYED:\n",
    "    deployment_state = \"deployed\"\n",
    "else:\n",
    "    deployment_state = \"undeployed\"\n",
    "\n",
    "# Display the model information.\n",
    "print(\"Model name: {}\".format(model.name))\n",
    "print(\"Model id: {}\".format(model.name.split(\"/\")[-1]))\n",
    "print(\"Model display name: {}\".format(model.display_name))\n",
    "print(\"Model create time:\")\n",
    "print(\"\\tseconds: {}\".format(model.create_time.seconds))\n",
    "print(\"\\tnanos: {}\".format(model.create_time.nanos))\n",
    "print(\"Model deployment state: {}\".format(deployment_state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 5: Evaluate the model</b> ##\n",
    "\n",
    "After training a model, Cloud AutoML Vision Object Detection uses images from the TEST image set to evaluate the quality and accuracy of the new model.\n",
    "\n",
    "It provides an aggregate set of evaluation metrics indicating how well the model performs overall, as well as evaluation metrics for each category label, indicating how well the model performs for that label.\n",
    "\n",
    "By running the cell below you can list evaluation metrics for that model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"List of model evaluations:\")\n",
    "for evaluation in client.list_model_evaluations(model_full_id, \"\"):\n",
    "    print(\"Model evaluation name: {}\".format(evaluation.name))\n",
    "    print(\n",
    "        \"Model annotation spec id: {}\".format(\n",
    "            evaluation.annotation_spec_id\n",
    "        )\n",
    "    )\n",
    "    print(\"Create Time:\")\n",
    "    print(\"\\tseconds: {}\".format(evaluation.create_time.seconds))\n",
    "    print(\"\\tnanos: {}\".format(evaluation.create_time.nanos / 1e9))\n",
    "    print(\n",
    "        \"Evaluation example count: {}\".format(\n",
    "            evaluation.evaluated_example_count\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Object detection model evaluation metrics: {}\\n\\n\".format(\n",
    "            evaluation.image_object_detection_evaluation_metrics\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 6: Deploy the model</b> ##\n",
    "\n",
    "Once we are happy with the performance of our trained model, we can deploy it so that it will be\n",
    "available for predictions through an API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.deploy_model(model_full_id)\n",
    "\n",
    "print(\"Model deployment finished. {}\".format(response.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## <b>Step 7: Send prediction request</b> ##\n",
    "\n",
    "In this example we will invoke an individual prediction from an image that is stored in our project's Cloud storage bucket.\n",
    "Object detection models output many bounding boxes for an input image. For the output we are expecting that each box comes with:\n",
    "1. a label and \n",
    "1. a score of confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGE_PATH = \"gs://your-bucket-name-vcm/your-folder-name/your-image.jpg\" # Replace with a Cloud storage bucket uploaded image of your choice\n",
    "\n",
    "prediction_client = automl.PredictionServiceClient()\n",
    "\n",
    "# Read the file.\n",
    "with tf.io.gfile.GFile(TEST_IMAGE_PATH, \"rb\") as content_file:\n",
    "    content = content_file.read()\n",
    "\n",
    "image = automl.types.Image(image_bytes=content)\n",
    "payload = automl.types.ExamplePayload(image=image)\n",
    "\n",
    "# params is additional domain-specific parameters.\n",
    "# score_threshold is used to filter the result\n",
    "# https://cloud.google.com/automl/docs/reference/rpc/google.cloud.automl.v1#predictrequest\n",
    "params = {\"score_threshold\": \"0.8\"}\n",
    "\n",
    "response = prediction_client.predict(model_full_id, payload, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the response object from the deployed model, we can inspect its predictions (i.e., the\n",
    "bounding boxes and objects that the model has detected from the images we sent to it in the cell above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Prediction results:\")\n",
    "for result in response.payload:\n",
    "    print(\"Predicted class name: {}\".format(result.display_name))\n",
    "    print(\n",
    "        \"Predicted class score: {}\".format(\n",
    "            result.image_object_detection.score\n",
    "        )\n",
    "    )\n",
    "    bounding_box = result.image_object_detection.bounding_box\n",
    "    print(\"Normalized Vertices:\")\n",
    "    for vertex in bounding_box.normalized_vertices:\n",
    "        print(\"\\tX: {}, Y: {}\".format(vertex.x, vertex.y))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
