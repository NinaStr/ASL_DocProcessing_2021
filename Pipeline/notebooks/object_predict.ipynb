{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8227ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49906a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO LIST\n",
    "#1- Change reading files to filter pdfs.\n",
    "#2- Access to the image classification end point\n",
    "#3- Create a JSON input for the endpoint (with the image)\n",
    "#4- Retrieve prediction\n",
    "#5- Store the prediction in a new BQ table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29dbb37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "598455e2",
   "metadata": {},
   "source": [
    "# Object Predictions Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d144a",
   "metadata": {},
   "source": [
    "## 1. Notebook Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bef4e0",
   "metadata": {},
   "source": [
    "### 1.1. Loading Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f633db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.7/site-packages (2.0.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "poppler-data is already the newest version (0.4.9-2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "poppler-utils is already the newest version (0.71.0-5).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 1 not upgraded.\n",
      "Requirement already satisfied: pdf2image in /opt/conda/lib/python3.7/site-packages (1.16.0)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.7/site-packages (from pdf2image) (8.3.1)\n"
     ]
    }
   ],
   "source": [
    "# General libraries:\n",
    "import os\n",
    "import io\n",
    "#import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Dealing with files:\n",
    "!pip install jsonlines\n",
    "import jsonlines\n",
    "import json\n",
    "\n",
    "# Dealing with images:\n",
    "#import cv2\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Google APIs:\n",
    "from google.cloud import storage\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform.gapic.schema import predict\n",
    "\n",
    "# Libraries for string filtering:\n",
    "from fnmatch import fnmatch\n",
    "\n",
    "# Libraries for image encoding\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Specific PDF libraries:\n",
    "#!conda install -c conda-forge poppler\n",
    "!sudo apt-get install -y poppler-data\n",
    "!sudo apt-get install -y poppler-utils\n",
    "!pip install pdf2image\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2c7c3",
   "metadata": {},
   "source": [
    "### 1.2. Setting Notebook Inputs\n",
    "#### 1.2.1 Google Cloud Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "198314de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ai]\n",
      "region = us-central1\n",
      "[core]\n",
      "account = 136021895401-compute@developer.gserviceaccount.com\n",
      "disable_usage_reporting = True\n",
      "project = qwiklabs-gcp-00-373ac55d0e0a\n",
      "\n",
      "Your active configuration is: [default]\n"
     ]
    }
   ],
   "source": [
    "!gcloud config list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77e00fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'qwiklabs-gcp-00-373ac55d0e0a'\n",
    "REGION = 'us-central1'\n",
    "BUCKET = 'qwiklabs-gcp-00-373ac55d0e0a'\n",
    "\n",
    "TEMP_FOLDER = './temp'\n",
    "RESULTS_CSV = 'img_class_results.csv'\n",
    "PREDICTION_MODE = 'BATCH' # 'ONLINE would be another possibility, but it is not implemented.'\n",
    "\n",
    "\n",
    "#PDF_FOLDER = os.path.join(TEMP_FOLDER, 'pdf')\n",
    "#PNG_FOLDER = os.path.join(TEMP_FOLDER, 'png')\n",
    "#CSV_FOLDER = os.path.join(TEMP_FOLDER, 'csv')\n",
    "\n",
    "os.environ['PROJECT'] = PROJECT\n",
    "os.environ['REGION'] = REGION\n",
    "os.environ['BUCKET'] = BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef4642a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "ENDPOINT_ID          DISPLAY_NAME\n",
      "3651416543192940544  text_classification_endpoint_V1\n",
      "2074030773706424320  ObjectDetectionV1\n",
      "7257673944809865216  image_classification_endpoint\n",
      "6387142210587983872  mnist_endpoint_20210802_154025\n",
      "4739387696923803648  babyweight_endpoint_20210730_125424\n",
      "5884427902182752256  babyweight_endpoint_20210730_124945\n",
      "61273583992700928    pipelines-EndpointCreate-20210727125838\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai endpoints list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb342950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "MODEL_ID             DISPLAY_NAME\n",
      "2393478483993952256  text_classification\n",
      "3409814256151953408  object_detection_patent_figures\n",
      "8925034949820547072  docprocessing_2021811144149\n",
      "2880236679656898560  hacker_news_titles_automl\n",
      "886021654033989632   mnist_20210802_154025\n",
      "2243012516756062208  babyweight_model_20210730_125424\n",
      "8763802564723474432  babyweight_model_20210730_124945\n",
      "5534440156922118144  babyweight_automl_2021728151029\n",
      "5491655960462098432  pipelines-ModelUpload-20210727125838\n",
      "657604710433292288   taxifare-20210721144351\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai models list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1589b6b",
   "metadata": {},
   "source": [
    "#### 1.2.2. Image Classification Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de5a62a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IC_ENDPOINT_ID=\"7257673944809865216\"\n",
    "IC_PROJECT_ID=\"136021895401\"\n",
    "IC_INPUT_DATA_FILE=\"INPUT-JSON\"\n",
    "\n",
    "# Example of instance:\n",
    "# {\n",
    "#  \"instances\": [{\n",
    "#    \"content\": \"YOUR_IMAGE_BYTES\"\n",
    "#  }],\n",
    "#   \"parameters\": {\n",
    "#     \"confidenceThreshold\": 0.5,\n",
    "#     \"maxPredictions\": 5\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f4a68c",
   "metadata": {},
   "source": [
    "#### 1.2.3. Object Detection Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47c15e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OD_ENDPOINT_ID=\"2074030773706424320\"\n",
    "# OD_PROJECT_ID=\"136021895401\"  \n",
    "OD_INPUT_DATA_FILE=\"INPUT-JSON\"\n",
    "\n",
    "# Example of instance:\n",
    "# {\n",
    "#  \"instances\": [{\n",
    "#    \"content\": \"YOUR_IMAGE_BYTES\"\n",
    "#  }],\n",
    "#   \"parameters\": {\n",
    "#     \"confidenceThreshold\": 0.5,\n",
    "#     \"maxPredictions\": 5\n",
    "#   }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74bfd4",
   "metadata": {},
   "source": [
    "## 2 Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe0c1269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bucket_file_list(bucket_name, fname_template='*'):\n",
    "    '''!@brief Function that returns the list of files in a bucket.\n",
    "    @param bucket (string) Bucket name.\n",
    "    @param fname_template (string) Template for filtering blob names \n",
    "    that supports Unix shell-style wildcards. For more info: \n",
    "    https://docs.python.org/3/library/fnmatch.html\n",
    "            \n",
    "    @return (list of srtings) List of blob names in a bucket which \n",
    "    fullfills template structure.\n",
    "    '''\n",
    "    # Instantiating client:\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    # Note: Client.list_blobs requires at least package version 1.17.0.\n",
    "    blobs = storage_client.list_blobs(bucket_name)\n",
    "    \n",
    "    # Listing all the blobs in a bucket:\n",
    "    blob_lst = [blob.name for blob in blobs]\n",
    "\n",
    "    # Filtering blob names with the template format given:  \n",
    "    file_lst = [fname for fname in blob_lst if fnmatch(fname, fname_template)]\n",
    "    \n",
    "    return file_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "531bf13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bucket(bucket_name, filter =['xxsdsdsds']):\n",
    "    # bucket_name = \"your-bucket-name\"\n",
    "    # blob_name = \"your-object-name\"\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    for file in filter:\n",
    "        blob = bucket.blob(file)\n",
    "        blob.delete()\n",
    "        print(\"Blob {} deleted.\".format(file))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbf33988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files_from_bucket(bucket_name, dest_folder, source_folder=\"labeled_patents/pdf/\", ext = \".pdf\" ):\n",
    "    '''@brief! Function that downloads a list of files from a bucket.\n",
    "\n",
    "    @param bucket: (string) Bucket name.\n",
    "    @param dest_folder: (string) Folder where files are downloaded.\n",
    "    '''\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "        \n",
    "    new_file_lst = []\n",
    "    # Instantiating client:\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    blob_list  = [blob for blob in list(bucket.list_blobs()) if blob.name.startswith(source_folder) and blob.name.endswith(ext)]\n",
    "\n",
    "    # Saving blob into the destination folder:\n",
    "    for blob in blob_list:\n",
    "        # Saving blob into a filename:\n",
    "        _, name = os.path.split(blob.name)\n",
    "        new_fname = os.path.join(dest_folder, name)\n",
    "        blob.download_to_filename(new_fname)\n",
    "        new_file_lst.append(new_fname)\n",
    "    \n",
    "    # TODO: A check of the downloaded files should be performed!! Maybe is just \n",
    "    # reading the files of the folder since if it is a temporal folder, every time\n",
    "    # the pipeline is executed, the folder is created empty:\n",
    "    #os.listdir(dest_folder) or similar\n",
    "    print('Number of files downloaded: {:d}'.format(len(new_file_lst)))\n",
    "    \n",
    "    return new_file_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7799d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_images_in_path(path):\n",
    "    '''@brief! Function to encode an image of each pdf to be used as instance \n",
    "    for a AutoML mode.\n",
    "        \n",
    "    @param file_lst (list of strings) PDF file names to be transformed.\n",
    "    '''\n",
    "    file_lst = [os.path.join(path, file) for file in os.listdir(path) if os.path.isfile(os.path.join(path, file))]\n",
    "    \n",
    "    encoded_img_lst = []\n",
    "    for file in file_lst:\n",
    "        image = convert_from_path(file)\n",
    "        image = image[0]                # Only the firs page is going to be analyzed.\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        image.save(img_byte_arr, format='PNG')\n",
    "        img_byte_arr = img_byte_arr.getvalue()\n",
    "        encoded_img_lst.append(base64.b64encode(img_byte_arr).decode(\"utf-8\"))\n",
    "\n",
    "    return encoded_img_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65f1b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to create JSONL files for instance creation:\n",
    "# WATCH OUT!! Hardcoded values!!\n",
    "def save_jsonl(fp, json_file):\n",
    "    # needs .jl suffix\n",
    "    d = json.dumps(json_file)+\"\\n\"\n",
    "    d = d.encode('utf8')\n",
    "    try:\n",
    "        with open(fp, \"ab\") as f:\n",
    "            f.write(d)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR]: {e}\\n{sys.exc_info()}\\n{traceback.format_exc()}\")\n",
    "\n",
    "def create_jsonl(gcs_img_path,fp):\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(BUCKET)\n",
    "    # create jsonl\n",
    "    blob_list  = [blob.name for blob in list(bucket.list_blobs()) if blob.name.startswith(\"labeled_patents/images\") and blob.name.endswith(\".png\")]\n",
    "    \n",
    "    for filename in blob_list:\n",
    "        temp_json = {\"content\": f\"gs://{BUCKET}/{filename}\", \"mimeType\": \"image/png\"}\n",
    "        save_jsonl(fp, temp_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2efee9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching batch predictions:\n",
    "def create_batch_prediction_job_sample(\n",
    "    project='qwiklabs-gcp-00-373ac55d0e0a',\n",
    "    location='us-central1',\n",
    "    model_resource_name='8925034949820547072',\n",
    "    job_display_name='batch_img_classification',\n",
    "    gcs_source='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images_icn.jsonl',\n",
    "    gcs_destination='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/img_class_preds'):\n",
    "    aiplatform.init(project=project, location=location)\n",
    "\n",
    "    my_model = aiplatform.Model(model_resource_name)\n",
    "\n",
    "    batch_prediction_job = my_model.batch_predict(\n",
    "        job_display_name=job_display_name,\n",
    "        gcs_source=gcs_source,\n",
    "        gcs_destination_prefix=gcs_destination,\n",
    "        sync=True,\n",
    "    )\n",
    "\n",
    "    batch_prediction_job.wait()\n",
    "\n",
    "    print(batch_prediction_job.display_name)\n",
    "    print(batch_prediction_job.resource_name)\n",
    "    print(batch_prediction_job.state)\n",
    "    return batch_prediction_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "384a2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_imgclass_results_from_jsonl(filename):\n",
    "   \n",
    "    # Creating an empty dataframe to store the image prediction results:\n",
    "    results_df = pd.DataFrame(columns=['image_name', 'label', 'confidence', 'x1', 'y1', 'x2', 'y2'])\n",
    "\n",
    "    \n",
    "    \n",
    "    # Reading the JSONL file and processing each JSON:\n",
    "    with jsonlines.open(filename, 'r') as file:\n",
    "        for i, line in enumerate(file):\n",
    "            # Extracting results from the jsonl file:\n",
    "            _, image_name = os.path.split(line['instance']['content'])\n",
    "            confidence = line['prediction']['confidences'][0]\n",
    "            label = line['prediction']['displayNames'][0]\n",
    "            x1,x2,y1,y2 = line['prediction']['bboxes'][0]\n",
    "                                  \n",
    "            # Storing results into a dataframe:\n",
    "            results_df.loc[i, 'image_name'] = image_name \n",
    "            results_df.loc[i, 'label'] = label\n",
    "            results_df.loc[i, 'confidence'] = confidence\n",
    "            results_df.loc[i, 'x1'] = x1\n",
    "            results_df.loc[i, 'x2'] = x2\n",
    "            results_df.loc[i, 'y1'] = y1\n",
    "            results_df.loc[i, 'y2'] = y2\n",
    "            \n",
    "        \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbc4b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"instance\":\n",
    " {\"content\":\"gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/images/espacenet_en77.png\",\"mimeType\":\"image/png\"},\n",
    " \"prediction\":{\"ids\":[\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\",\"4025440712148385792\"],\"displayNames\":[\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\",\"figure\"],\"confidences\":[0.76443034,0.52859145,0.061091945,0.047826927,0.04333216,0.041156087,0.024904016,0.016526928,0.0154661825,0.009587449,0.0059969747,0.0049217422,0.003716267,0.0018125111,0.0014895669,9.770558E-4,6.6138944E-4,5.448992E-4,5.160438E-4,4.719642E-4,3.8369338E-4,1.9644677E-4,1.17846575E-4,9.965644E-5,9.641395E-5,4.864133E-5,4.8306472E-5,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"bboxes\":[[0.52033967,0.9044393,0.5511127,0.86246306],[0.41000938,0.9396043,0.53035796,0.93202925],[0.0,0.83526015,0.75827837,0.9620595],[0.21463868,1.0,0.59826696,0.8279809],[0.0037953723,0.84061676,0.8309676,0.9734295],[0.0,0.56297934,0.7997256,0.95936674],[0.3143646,1.0,0.7920224,0.9654812],[0.2724947,1.0,0.8544905,0.9779967],[0.19053939,1.0,0.6729741,0.9295645],[0.050835077,0.5335755,0.0,0.15947065],[0.05325192,0.77883846,0.6753786,0.8990497],[0.006186412,0.41803375,0.0,0.24027358],[0.0,0.9708189,0.001218386,0.13738793],[0.0,0.91130924,0.0,0.31182438],[0.37795317,0.95148355,0.5103226,0.7134304],[0.11684726,0.81253517,0.58722883,0.8011121],[0.13189778,0.9944205,0.0,0.19389042],[0.3499291,0.9611198,0.46038198,0.65194726],[0.010287788,0.2654363,0.0,0.4094497],[0.2323548,0.95879376,0.42165536,0.6178679],[0.10978146,0.76506,0.51294935,0.7306119],[0.24385671,0.953726,0.06038098,0.36443573],[0.07948293,0.76043177,0.070823476,0.41676348],[0.05707376,0.71713334,0.41747388,0.64191526],[0.33629754,0.9581925,0.31212947,0.5304564],[0.3047768,0.9329275,0.20252322,0.45437324],[0.041961167,0.67546207,0.3167929,0.5543516],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0]]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f775022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8450b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file_to_bucket(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"!@brief Function that uploads a file to a bucket.\n",
    "    \n",
    "    @param bucket_name (string) ID/name of the bucket.\n",
    "    @param source_file_name (string) Path to the file to be uploaded.\n",
    "    @param destination_blob_name (string) Desired storage object name.   \n",
    "    \"\"\"\n",
    "    \n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "\n",
    "    print(\"File {} uploaded to {}.\".format(source_file_name, destination_blob_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1b50fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_from_csv(dataset_name, table_name, schema_lst, csv_blob_name):\n",
    "    '''!@brief Function that create a table in an existing dataset with\n",
    "    the data contained into a CSV.\n",
    "    \n",
    "    @param dataset_name (string) Name of the dataset which will store \n",
    "    the table.\n",
    "    @param table_name (string) Name of the table to be created.\n",
    "    @param schema_lst (list of tuples) Contains the schema of the table\n",
    "    to be created. The format must be the next one: \n",
    "    [()'column name', 'field format', 'mode', 'Description')]\n",
    "    Example:\n",
    "    schema_lst = [('col_A_name',  'STRING', 'REQUIRED', 'Description 1'), \n",
    "                  ('col_B_name', 'INTEGER', 'REQUIRED', 'Description 2'),\n",
    "                  ('col_C_name',   'FLOAT', 'REQUIRED', 'Description 3')]\n",
    "    For more info:\n",
    "    https://cloud.google.com/bigquery/docs/reference/rest/v2/tables#TableFieldSchema.FIELDS.type\n",
    "    @param csv_blob_name (string) GS URI of the CSV file.\n",
    "    '''\n",
    "    \n",
    "    # Construct a BigQuery client object.\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Setting table_id to the ID of the table to create.\n",
    "    table_id = \"{}.{}.{}\".format(client.project, dataset_name, table_name)\n",
    "    \n",
    "    # Creating table schema:\n",
    "    schema = [bigquery.SchemaField(*tup) for tup in schema_lst]\n",
    "    \n",
    "    # Configuring the job which builds the table:\n",
    "    job_config = bigquery.LoadJobConfig(schema=schema,\n",
    "                                        skip_leading_rows=1,\n",
    "                                        source_format=bigquery.SourceFormat.CSV)\n",
    "\n",
    "    # Making an API request to create the job:\n",
    "    load_job = client.load_table_from_uri(csv_blob_name, table_id, job_config=job_config)\n",
    "\n",
    "    # Waiting for the job to be completed.\n",
    "    load_job.result()\n",
    "\n",
    "    destination_table = client.get_table(table_id)  # Make an API request.\n",
    "    print(\"Loaded {} rows.\".format(destination_table.num_rows))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac15703",
   "metadata": {},
   "source": [
    "## 3. Pipeline Functional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685b883",
   "metadata": {},
   "source": [
    "### 3.1. Download PDFs to a temporal folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8b6b21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files downloaded: 403\n"
     ]
    }
   ],
   "source": [
    "# Creating the temporal folder if it does not exists:\n",
    "if not os.path.exists(TEMP_FOLDER):\n",
    "    # Create folder:\n",
    "    os.mkdir(TEMP_FOLDER)\n",
    "    \n",
    "# Downloading PDFs from the bucket to the temporal folder:\n",
    "file_lst = download_files_from_bucket(BUCKET, TEMP_FOLDER, source_folder=\"labeled_patents/pdf/\", ext = \".pdf\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192cdcf",
   "metadata": {},
   "source": [
    "### 3.2. Transforming PDFs into PNGs (Only for Online prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5c9c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'ONLINE'==PREDICTION_MODE:\n",
    "    # Encoding images as base64:\n",
    "    imgs = encode_images_in_path(dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc401969",
   "metadata": {},
   "source": [
    "### 3.3. Cleaning old predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14518f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist = get_bucket_file_list(BUCKET, fname_template='*obj_preds*.jsonl')\n",
    "clean_bucket(BUCKET, filelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a68d14",
   "metadata": {},
   "source": [
    "### 3.4. Performing predictions in the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ca2742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://./obj_inputs.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1/1 files][ 44.8 KiB/ 44.8 KiB] 100% Done                                    \n",
      "Operation completed over 1 objects/44.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "# Creating the batch of instances to perform a prediction:\n",
    "import json\n",
    "gcs_img_path = f\"gs:/{PROJECT}/{BUCKET}/labeled_patents/images\"\n",
    "fp = \"obj_inputs.jsonl\"\n",
    "        \n",
    "# Creating the JSONL file with all the instances:\n",
    "create_jsonl(gcs_img_path, fp)\n",
    "\n",
    "# Uploading the JSONL file to a bucket:\n",
    "!gsutil -m cp ./obj_inputs.jsonl gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6d1dd883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074030773706424320\n"
     ]
    }
   ],
   "source": [
    "!echo $OD_ENDPOINT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5ba4571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "MODEL_ID             DISPLAY_NAME\n",
      "2393478483993952256  text_classification\n",
      "3409814256151953408  object_detection_patent_figures\n",
      "8925034949820547072  docprocessing_2021811144149\n",
      "2880236679656898560  hacker_news_titles_automl\n",
      "886021654033989632   mnist_20210802_154025\n",
      "2243012516756062208  babyweight_model_20210730_125424\n",
      "8763802564723474432  babyweight_model_20210730_124945\n",
      "5534440156922118144  babyweight_automl_2021728151029\n",
      "5491655960462098432  pipelines-ModelUpload-20210727125838\n",
      "657604710433292288   taxifare-20210721144351\n"
     ]
    }
   ],
   "source": [
    "!gcloud ai models list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be075c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784\n",
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784')\n",
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/4312761792183926784?project=136021895401\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/136021895401/locations/us-central1/batchPredictionJobs/4312761792183926784 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "# Launching predictions:\n",
    "create_batch_prediction_job_sample(\n",
    "    project='qwiklabs-gcp-00-373ac55d0e0a',\n",
    "    location='us-central1',\n",
    "    model_resource_name='3409814256151953408',\n",
    "    job_display_name='obj_predictions',\n",
    "    gcs_source='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/obj_inputs.jsonl',\n",
    "    gcs_destination='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/obj_preds')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0196241",
   "metadata": {},
   "source": [
    "### 3.5. Downloding the JSONL files with the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6114f92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files downloaded: 5\n",
      "\n",
      "Downloaded files:\n",
      "./temp/predictions_00001.jsonl\n",
      "./temp/predictions_00002.jsonl\n",
      "./temp/predictions_00003.jsonl\n",
      "./temp/predictions_00004.jsonl\n",
      "./temp/predictions_00005.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Downloading the results files from Google Storage:\n",
    "#gcs_destination='gs://qwiklabs-gcp-00-373ac55d0e0a/labeled_patents/obj_preds'\n",
    "source_folder = 'labeled_patents/obj_preds' \n",
    "ext = \".jsonl\"\n",
    "resfile_lst = download_files_from_bucket(BUCKET, TEMP_FOLDER, source_folder, ext)\n",
    "\n",
    "print('\\nDownloaded files:')\n",
    "print(*resfile_lst, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0041214",
   "metadata": {},
   "source": [
    "### 3.6. Parsing the predictions from the JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71007bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of results read: 403\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>espacenet_en77.png</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.76443</td>\n",
       "      <td>0.52034</td>\n",
       "      <td>0.551113</td>\n",
       "      <td>0.904439</td>\n",
       "      <td>0.862463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>us_027.png</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.820037</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>0.676503</td>\n",
       "      <td>0.773016</td>\n",
       "      <td>0.915524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>computer_vision_12.png</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.863901</td>\n",
       "      <td>0.175164</td>\n",
       "      <td>0.720555</td>\n",
       "      <td>0.748335</td>\n",
       "      <td>0.931796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>espacenet_en35.png</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.162117</td>\n",
       "      <td>0.319214</td>\n",
       "      <td>0.625916</td>\n",
       "      <td>0.895415</td>\n",
       "      <td>0.902939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us_087.png</td>\n",
       "      <td>figure</td>\n",
       "      <td>0.85913</td>\n",
       "      <td>0.324708</td>\n",
       "      <td>0.697885</td>\n",
       "      <td>0.642282</td>\n",
       "      <td>0.945174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               image_name   label confidence        x1        y1        x2  \\\n",
       "0      espacenet_en77.png  figure    0.76443   0.52034  0.551113  0.904439   \n",
       "1              us_027.png  figure   0.820037  0.249958  0.676503  0.773016   \n",
       "2  computer_vision_12.png  figure   0.863901  0.175164  0.720555  0.748335   \n",
       "3      espacenet_en35.png  figure   0.162117  0.319214  0.625916  0.895415   \n",
       "4              us_087.png  figure    0.85913  0.324708  0.697885  0.642282   \n",
       "\n",
       "         y2  \n",
       "0  0.862463  \n",
       "1  0.915524  \n",
       "2  0.931796  \n",
       "3  0.902939  \n",
       "4  0.945174  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parsing the JSONL files:\n",
    "for i, file in enumerate(resfile_lst):\n",
    "    if i==0:\n",
    "        res_df = read_imgclass_results_from_jsonl(file)\n",
    "    else:\n",
    "        res_df = res_df.append(read_imgclass_results_from_jsonl(file))\n",
    "        \n",
    "print('Number of results read: {:d}'.format(res_df.shape[0]))\n",
    "res_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd91005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94d5eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the results dataframe as a CSV file:\n",
    "res_df.to_csv(os.path.join(TEMP_FOLDER, RESULTS_CSV), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f3562",
   "metadata": {},
   "source": [
    "### 3.7.Upload results to a BQ table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e06abd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./temp/img_class_results.csv uploaded to labeled_patents/obj_preds/img_class_results.csv.\n"
     ]
    }
   ],
   "source": [
    "# Uploading the CSV file to a GS bucket:\n",
    "upload_file_to_bucket(bucket_name=BUCKET, \n",
    "                      source_file_name=os.path.join(TEMP_FOLDER, RESULTS_CSV), \n",
    "                      destination_blob_name=os.path.join('labeled_patents', 'obj_preds', RESULTS_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2fb16c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 403 rows.\n"
     ]
    }
   ],
   "source": [
    "# Storing the CSV content into a BQ table:\n",
    "dataset_name = 'labeled_patents'\n",
    "table_name = 'image_classification_results'\n",
    "schema_lst = [('image_name', 'STRING', 'REQUIRED', 'Name of the image analyzed.'), \n",
    "              ('label',      'STRING', 'REQUIRED', 'Predicted class. It can be US or EU'),\n",
    "              ('confidence',  'FLOAT', 'REQUIRED', 'Confidence of the prediction.')]\n",
    "csv_blob_name = os.path.join('gs://', BUCKET, 'labeled_patents', 'img_class_preds', RESULTS_CSV)\n",
    "\n",
    "create_table_from_csv(dataset_name, table_name, schema_lst, csv_blob_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7768644f",
   "metadata": {},
   "source": [
    "### 3.8. Cleaning temporal folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1774412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the temporal folder:\n",
    "os.rmdir(TEMP_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb2fe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m76",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m76"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
