{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27ae6653",
   "metadata": {},
   "source": [
    "# Prepare pdfs for later in pipeline (Obj Det, Img, text, NER)\n",
    "\n",
    "- user provides\n",
    "    - Google Cloud project (input)\n",
    "    - bucket in GCS of pdfs (input)\n",
    "    - BQ dataset to write prediction results (output)\n",
    "        - BQ table: aggregated results (pdf_name, icn_pred, objdet_pred(coords), text_cn, ner1, ner2, ...., ner)\n",
    "            created with JOIN on pdf_name\n",
    "        - BQ table: icn_preds (pdf_name, icn_pred)    --> this table is made in icn_predict.ipynb\n",
    "        - BQ table: objdet_pred (pdf_name, objdet_pred(coords)) --> this table is made in objdet_predict.ipynb\n",
    "        - BQ table: text_cn (pdf_name, text_cn)    --> this table is made in text_cn_predict.ipynb\n",
    "        - BQ table: ner (pdf_name, ner1, ner2, ...., ner)\n",
    "        \n",
    "- see utils.py for utils functions\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8bd519",
   "metadata": {},
   "source": [
    "Steps: \n",
    " 1. convert pdf to png and write to bucket (for ICN, ObjDet)\n",
    " 2. do ocr on pdf and write to bucket \n",
    " 3. create dataset \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f1b5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = !gcloud config get-value project # returns SList\n",
    "PROJECT = PROJECT[0] # gets first element in list -> str\n",
    "REGION = \"us-central1\"  \n",
    "MODEL_RESOURCE_NAME = \"2393478483993952256\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PROJECT\"] = PROJECT\n",
    "os.environ[\"REGION\"] = REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7c7f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "bq = bigquery.Client(project=PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d5bd5d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5744d510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "from google.cloud import vision\n",
    "import tempfile\n",
    "import traceback as tb\n",
    "from importlib import reload\n",
    "\n",
    "# for jupyter only\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.DEBUG, datefmt='%I:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db0ed750",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import io\n",
    "import base64\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21a05e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:29:22 INFO:test if logging works\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"test if logging works\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4bf6edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_trace_str(e):\n",
    "    return ''.join(tb.format_exception(None, e, e.__traceback__))\n",
    "\n",
    "class Utils():\n",
    "    def __init__(self):\n",
    "        self.storage_client = storage.Client()\n",
    "        \n",
    "    def __dismantle_path(self, gcs_path):\n",
    "        directory = os.path.splitext(gcs_path)[1]\n",
    "        bucket_name =  os.path.splitext(gcs_path)[0].replace(\"gs://\",\"\")\n",
    "        \n",
    "        return bucket_name, directory\n",
    "        \n",
    "    \n",
    "    def convert_pdf_to_png(self, src_path, dst_path):\n",
    "        \"\"\"Takes pdfs from src_bucket_name and transforms them into png. Then it saves the result in dst_bucket_name\"\"\"\n",
    "        try:\n",
    "            logging.info(\"started conversion pdf -> png\")\n",
    "        \n",
    "            src_bucket_name, src_directory = self.__dismantle_path(src_path)\n",
    "            dst_bucket_name, dst_directory = self.__dismantle_path(dst_path)\n",
    "            \n",
    "            src_bucket = self.storage_client.bucket(src_bucket_name)\n",
    "            dst_bucket = self.storage_client.bucket(dst_bucket_name)\n",
    "\n",
    "            blob_list = [blob for blob in list(src_bucket.list_blobs()) if \\\n",
    "                         os.path.basename(src_directory) in blob.name and \\\n",
    "                         blob.name.endswith(\".pdf\")]\n",
    "\n",
    "            encoded_img_lst = []\n",
    "            imgs = []\n",
    "            logging.info(f\"found {len(blob_list)} pdfs in bucket  {src_bucket_name}\")\n",
    "\n",
    "            for b_idx, blob in enumerate(blob_list):\n",
    "                _, tmp_pdf = tempfile.mkstemp()\n",
    "                blob.download_to_filename(tmp_pdf)\n",
    "                logging.info(f\"downloaded {b_idx+1} of {len(blob_list)} files\")\n",
    "                image = convert_from_path(tmp_pdf)\n",
    "                logging.info(f\"converted {b_idx+1} of {len(blob_list)} images\")\n",
    "                image = image[0]                # Only the firs page is going to be analyzed.\n",
    "                image = np.array(image)\n",
    "                is_success, im_buf_arr = cv2.imencode(\".png\", image)\n",
    "                byte_im = im_buf_arr.tobytes()\n",
    "                filename = os.path.join(dst_directory, blob.name+\".png\")\n",
    "                dst_bucket.blob(filename).upload_from_string(byte_im)\n",
    "                logging.info(f\"saved {b_idx+1} of {len(blob_list)} images with filename {filename}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in method convert_pdf_to_png: {to_trace_str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def ocr(self, src_path, dst_path):\n",
    "        \"\"\"Perform optical character recognition in pdf files.\n",
    "        \n",
    "        Args\n",
    "            src_path\n",
    "            dst_path\n",
    "        \n",
    "        Returns\n",
    "            google.api_core.operation.Operation\n",
    "            To check if done use method .done()\n",
    "            \n",
    "        Link to documentation:  \n",
    "            https://googleapis.dev/python/vision/latest/vision_v1/types.html#google.cloud.vision_v1.types.OutputConfig\n",
    "            https://cloud.google.com/vision/docs/pdf\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            logging.info(\"started optical character recognition\")\n",
    "        \n",
    "            src_bucket_name, src_directory = self.__dismantle_path(src_path)\n",
    "            dst_bucket_name, dst_directory = self.__dismantle_path(dst_path)\n",
    "            \n",
    "            src_bucket = self.storage_client.bucket(src_bucket_name)\n",
    "            dst_bucket = self.storage_client.bucket(dst_bucket_name)\n",
    "\n",
    "            blob_list = [blob for blob in list(src_bucket.list_blobs()) if \\\n",
    "                         os.path.basename(src_directory) in blob.name and \\\n",
    "                         blob.name.endswith(\".pdf\")]\n",
    "\n",
    "            client = vision.ImageAnnotatorClient()\n",
    "            feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "            \n",
    "            operations = []\n",
    "            async_requests = []\n",
    "            \n",
    "            for b_idx, blob in enumerate(blob_list):\n",
    "                gcs_source_uri = os.path.join(src_path, blob.name)\n",
    "                gcs_destination_uri = os.path.join(dst_path, blob.name)\n",
    "\n",
    "                # source\n",
    "                gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "                input_config = vision.InputConfig(gcs_source=gcs_source, mime_type='application/pdf')\n",
    "\n",
    "                # destination\n",
    "                gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "                output_config = vision.OutputConfig(gcs_destination=gcs_destination, batch_size=1)\n",
    "\n",
    "                logging.info(f\"started ocr for {b_idx} of {len(blob_list)} files\")\n",
    "                async_request = vision.AsyncAnnotateFileRequest(\n",
    "                    features=[feature], \n",
    "                    input_config=input_config,\n",
    "                    output_config=output_config\n",
    "                )\n",
    "                async_requests.append(async_request)\n",
    "\n",
    "            operation = client.async_batch_annotate_files(requests=async_requests)\n",
    "            return operation\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in method ocr: {to_trace_str(e)}\")\n",
    "        \n",
    "    \n",
    "    def convert_results_to_df(self, results):\n",
    "        pass\n",
    "    \n",
    "    def upload_csv_to_storage(self, csv_path, gcs_path):\n",
    "        pass\n",
    "    \n",
    "    def upload_csv_to_bigquery(self, csv_path, dataset_id, table_id, schema):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9d02a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01:19:29 INFO:started optical character recognition\n",
      "01:19:29 INFO:started ocr for 0 of 3 files\n",
      "01:19:29 INFO:started ocr for 1 of 3 files\n",
      "01:19:29 INFO:started ocr for 2 of 3 files\n"
     ]
    }
   ],
   "source": [
    "utils = Utils()\n",
    "src_path = \"gs://2021_08_16_tcn_dev\"\n",
    "dst_path = \"gs://2021_08_16_tcn_dev\"\n",
    "\n",
    "# utils.convert_pdf_to_png(src_path, dst_path)\n",
    "operations = utils.ocr(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5a8141ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'google.api_core.operation.Operation'>\n"
     ]
    }
   ],
   "source": [
    "op = operations[0]\n",
    "print(type(op))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "op.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c384798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883f91a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7e0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03703bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-5.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-5:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
